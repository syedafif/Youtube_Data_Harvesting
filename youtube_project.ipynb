{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pymongo\n",
    "import streamlit as st\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import isodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyCfUnVWf3_VbSqkEd6-vdM1LqLo9Uf3ujs\"\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(ch_details(ID))\n",
    "def ch_details(ID):\n",
    "    request = youtube.channels().list(part=\"snippet,contentDetails,statistics\", id=ID)\n",
    "    response = request.execute()\n",
    "    ch = dict(\n",
    "        channel_id=response['items'][0]['id'],\n",
    "        channel_name=response['items'][0]['snippet']['title'],\n",
    "        channel_publish=response['items'][0]['snippet']['publishedAt'],\n",
    "        channel_description=response['items'][0]['snippet']['description'],\n",
    "        channel_subscribercount=response['items'][0]['statistics']['subscriberCount'],\n",
    "        channel_videos=response['items'][0]['statistics']['videoCount'],\n",
    "        channel_views=response['items'][0]['statistics']['viewCount'],\n",
    "        playlist_id=response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    )\n",
    "    return ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video IDS\n",
    "def Video_IDs(ID):\n",
    "    video_ids = []\n",
    "    res = youtube.channels().list(id=ID,part='contentDetails').execute()\n",
    "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    next_page_token = None\n",
    "    while True:\n",
    "        res = youtube.playlistItems().list(part = 'snippet',playlistId = playlist_id,maxResults = 50,pageToken = next_page_token).execute()\n",
    "        for i in range(len(res['items'])):\n",
    "            video_ids.append(res['items'][i]['snippet']['resourceId']['videoId'])\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Details\n",
    "def video_details(video_ids):\n",
    "    video_data = []\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(part=\"snippet,contentDetails,statistics\",id= video_id)\n",
    "        response = request.execute()\n",
    "        for item in response[\"items\"]:\n",
    "            data = dict(Channel_Name = item['snippet']['channelTitle'],\n",
    "                        Channel_Id = item['snippet']['channelId'],\n",
    "                        Video_Id = item['id'],\n",
    "                        Title = item['snippet']['title'],\n",
    "                        Tags = item['snippet'].get('tags'),\n",
    "                        Thumbnail = item['snippet']['thumbnails']['default']['url'],\n",
    "                        Description = item['snippet']['description'],\n",
    "                        Published_Date = item['snippet']['publishedAt'],\n",
    "                        Duration = int(pd.Timedelta(item['contentDetails']['duration']).total_seconds()),\n",
    "                        Views = item['statistics']['viewCount'],\n",
    "                        Likes = item['statistics'].get('likeCount'),\n",
    "                        Comments = item['statistics'].get('commentCount'),\n",
    "                        Favorite_Count = item['statistics']['favoriteCount'],\n",
    "                        Definition = item['contentDetails']['definition'],\n",
    "                        Caption_Status = item['contentDetails']['caption']\n",
    "                        )\n",
    "            video_data.append(data)\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comment Details\n",
    "def comment_details(video_ids):\n",
    "    Comment_Data = []\n",
    "    try:\n",
    "        for video_id in video_ids:\n",
    "            request = youtube.commentThreads().list(part = \"snippet\",videoId = video_id,maxResults = 20)\n",
    "            response5 = request.execute()\n",
    "            for item in response5[\"items\"]:\n",
    "                comment_data = dict(\n",
    "                Comment_Id = item[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
    "                Video_Id = item[\"snippet\"][\"videoId\"],\n",
    "                Comment_Text = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textOriginal\"],\n",
    "                Comment_Author = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"],\n",
    "                Comment_Published = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"])\n",
    "            Comment_Data.append(comment_data)\n",
    "    except:\n",
    "        pass\n",
    "    return Comment_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect MongoDB\n",
    "from pymongo.mongo_client import MongoClient\n",
    "client = pymongo.MongoClient(\"mongodb+srv://syedafif9028:syed9028@cluster0.zukmabg.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db = client[\"Youtube_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL connection\n",
    "mydb = mysql.connector.connect(host=\"localhost\",\n",
    "                                user=\"root\",\n",
    "                                password=\"12345678\",\n",
    "                                database= \"youtube_datas\",\n",
    "                                port = \"3306\"\n",
    "                                )\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data To MongoDB Database\n",
    "def Channel_Details(ID):\n",
    "    Ch_details = ch_details(ID)\n",
    "    vi_id = Video_IDs(ID)\n",
    "    Vi_details = video_details(vi_id)\n",
    "    Com_details = comment_details(vi_id)\n",
    "    collection1 = db[\"Channel_Datas\"]\n",
    "    collection1.insert_one({\"Channel_Details\":Ch_details,\"Video_Details\":Vi_details,\n",
    "                            \"Comment_Details\":Com_details})\n",
    "    return \"upload completed successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Table\n",
    "def channels_table():\n",
    "    drop_query = \"drop table if exists channels\"\n",
    "    mycursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE channels (channel_id VARCHAR (80) primary key,\n",
    "                                                channel_name VARCHAR (100),\n",
    "                                                channel_publish timestamp,\n",
    "                                                channel_description text,\n",
    "                                                channel_subscribercount int,\n",
    "                                                channel_videos int,\n",
    "                                                channel_views int, \n",
    "                                                playlist_id VARCHAR (100))'''\n",
    "        mycursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Channels Table already created\")    \n",
    "    ch_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    collection1 = db[\"Channel_Datas\"]\n",
    "    for ch_data in collection1.find({\"Channel_Details.channel_name\":channel_names}):\n",
    "        ch_list.append(ch_data[\"Channel_Details\"])\n",
    "    df = pd.DataFrame(ch_list)\n",
    "    for index,row in df.iterrows():\n",
    "        insert_query = '''INSERT INTO channels (channel_id, channel_name, channel_publish, \n",
    "                                                channel_description, channel_subscribercount, \n",
    "                                                channel_videos, channel_views, playlist_id) \n",
    "                                                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "        values =(\n",
    "                row['channel_id'],\n",
    "                row['channel_name'],\n",
    "                row['channel_publish'],\n",
    "                row['channel_description'],\n",
    "                row['channel_subscribercount'],\n",
    "                row['channel_videos'],\n",
    "                row['channel_views'],\n",
    "                row['playlist_id'])\n",
    "        try:                     \n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()    \n",
    "        except:\n",
    "            pass\n",
    "    st.write(\"Channels values are already inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Table\n",
    "def videos_table():\n",
    "    drop_query = \"drop table if exists video\"\n",
    "    mycursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE videos (Channel_Name VARCHAR(100),\n",
    "                                                Channel_Id VARCHAR(100),\n",
    "                                                Video_Id VARCHAR(100) PRIMARY KEY,\n",
    "                                                Title VARCHAR(100),\n",
    "                                                Tags TEXT,\n",
    "                                                Thumbnail VARCHAR(255),\n",
    "                                                Description TEXT,\n",
    "                                                Published_Date TIMESTAMP,\n",
    "                                                Duration INT,\n",
    "                                                Views INT,\n",
    "                                                Likes INT,\n",
    "                                                Comments INT,\n",
    "                                                Favorite_Count INT,\n",
    "                                                Definition VARCHAR(100),\n",
    "                                                Caption_Status VARCHAR(100))'''\n",
    "        mycursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Video Table already created\")    \n",
    "    vi_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    collection1 = db[\"Channel_Datas\"]\n",
    "    for vi_data in collection1.find({\"Channel_Details.channel_name\":channel_names}):\n",
    "        for i in range(len(vi_data[\"Video_Details\"])):\n",
    "                vi_list.append(vi_data[\"Video_Details\"][i])\n",
    "    df = pd.DataFrame(vi_list)\n",
    "    for index,row in df.iterrows():\n",
    "        insert_query = '''INSERT INTO videos (Channel_Name, Channel_Id, \n",
    "                                                Video_Id, Title,    \n",
    "                                                Tags, Thumbnail, Description,\n",
    "                                                Published_Date,\n",
    "                                                Duration, Views, Likes,\n",
    "                                                Comments, Favorite_Count,\n",
    "                                                Definition, Caption_Status) \n",
    "                                                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''            \n",
    "        values =(\n",
    "                row['Channel_Name'],\n",
    "                row['Channel_Id'],\n",
    "                row['Video_Id'],\n",
    "                row['Title'],\n",
    "                row['Tags'],\n",
    "                row['Thumbnail'],\n",
    "                row['Description'],\n",
    "                row['Published_Date'],\n",
    "                row['Duration'],\n",
    "                row['Views'],\n",
    "                row['Likes'],\n",
    "                row['Comments'],\n",
    "                row['Favorite_Count'],\n",
    "                row['Definition'],\n",
    "                row['Caption_Status'])\n",
    "        try:                     \n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()    \n",
    "        except:\n",
    "            pass\n",
    "    st.write(\"Video values are inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments Table\n",
    "def comments_table():\n",
    "    drop_query = \"drop table if exists comment\"\n",
    "    mycursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        create_query = '''CREATE TABLE comments (Comment_Id VARCHAR (100) primary key,\n",
    "                                                    Video_Id VARCHAR (100),\n",
    "                                                    Comment_Text text,\n",
    "                                                    Comment_Author VARCHAR (100),\n",
    "                                                    Comment_Published timestamp)'''\n",
    "        mycursor.execute(create_query)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        st.write(\"Comment Table already created\")  \n",
    "    com_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    collection1 = db[\"Channel_Datas\"]\n",
    "    for com_data in collection1.find({\"Channel_Details.channel_name\":channel_names}):\n",
    "        for i in range(len(com_data[\"Comment_Details\"])):\n",
    "            com_list.append(com_data[\"Comment_Details\"][i])\n",
    "    df = pd.DataFrame(com_list)\n",
    "    for index,row in df.iterrows():\n",
    "        insert_query = '''INSERT INTO comments (Comment_Id, Video_Id, Comment_Text, \n",
    "                                        Comment_Author, Comment_Published) \n",
    "                                        VALUES (%s, %s, %s, %s, %s)'''            \n",
    "        values =(\n",
    "                row['Comment_Id'],\n",
    "                row['Video_Id'],\n",
    "                row['Comment_Text'],\n",
    "                row['Comment_Author'],\n",
    "                row['Comment_Published'])\n",
    "        try:                     \n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()    \n",
    "        except:\n",
    "            pass\n",
    "    st.write(\"Comments values are inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Tables\n",
    "def Tables():\n",
    "    channels_table()\n",
    "    videos_table()\n",
    "    comments_table()\n",
    "    return \"Tables Created Successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show channel table\n",
    "def show_channel_table():\n",
    "    ch_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    collection1 = db[\"Channel_Datas\"]\n",
    "    for ch_data in collection1.find({\"Channel_Details.channel_name\":channel_names}):\n",
    "        ch_list.append(ch_data[\"Channel_Details\"])\n",
    "    channels_table = st.dataframe(ch_list)\n",
    "    return channels_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show video table\n",
    "def show_video_table():\n",
    "    vi_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    collection1 = db[\"Channel_Datas\"]\n",
    "    for vi_data in collection1.find({\"Video_Details.Channel_Name\":channel_names}):\n",
    "        for i in range(len(vi_data[\"Video_Details\"])):\n",
    "            vi_list.append(vi_data[\"Video_Details\"][i])\n",
    "    video_table = st.dataframe(vi_list)\n",
    "    return video_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show comment table\n",
    "def show_comment_table():\n",
    "    com_list = []\n",
    "    db = client[\"Youtube_data\"]\n",
    "    collection1 = db[\"Channel_Datas\"]\n",
    "    for com_data in collection1.find({\"Channel_Details.channel_name\":channel_names}):\n",
    "        for i in range(len(com_data[\"Comment_Details\"])):\n",
    "            com_list.append(com_data[\"Comment_Details\"][i])\n",
    "    comment_table = st.dataframe(com_list)\n",
    "    return comment_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seconds to Duration\n",
    "def seconds_to_iso8601(average_duration):\n",
    "    hours = average_duration // 3600\n",
    "    minutes = (average_duration % 3600) // 60\n",
    "    average_duration = average_duration % 60\n",
    "    return f\"PT{hours}H{minutes}M{average_duration}S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streamlit\n",
    "st.title(\":rainbow[YouTube Data Harvesting and Warehousing :red[: ▶]]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Menu=st.sidebar.selectbox(\":red[*Please Select The Menu:-*]\",(\"Home\",\"Data Transfer\",\"Migrate Date\",\"Query\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Menu == \"Home\":\n",
    "    with st.sidebar:\n",
    "        st.header(\":red[Skill:-]\")\n",
    "        st.write(':blue[ :star: Python scripting]') \n",
    "        st.write(':blue[ :star: API Integration]')\n",
    "        st.write(':blue[ :star: Data Collection]')\n",
    "        st.write(':blue[ :star: MongoDB]')\n",
    "        st.write(':blue[ :star: Data Managment using MongoDB and SQL]')\n",
    "        st.write(':blue[ :star: Streamlit]')\n",
    "    st.header(\"*Project*\")\n",
    "    st.subheader(':gray[Set up a Streamlit app:-]') \n",
    "    st.write('Streamlit is a great choice for building data visualization and analysis tools quickly and easily. You can use Streamlit to create a simple UI where users can enter a YouTube channel ID, view the channel details, and select channels to migrate to the data warehouse.')\n",
    "    st.subheader(':gray[Connect to the YouTube API:-]') \n",
    "    st.write(\"You'll need to use the YouTube API to retrieve channel and video data. You can use the Google API client library for Python to make requests to the API.\")\n",
    "    st.subheader(':gray[Store data in a MongoDB data lake:-]') \n",
    "    st.write(\"Once you retrieve the data from the YouTube API, you can store it in a MongoDB data lake. MongoDB is a great choice for a data lake because it can handle unstructured and semi-structured data easily.\")\n",
    "    st.subheader(':gray[Migrate data to a SQL data warehouse:-]') \n",
    "    st.write(\"After you've collected data for multiple channels, you can migrate it to a SQL data warehouse. You can use a SQL database such as MySQL or PostgreSQL for this.\")\n",
    "    st.subheader(':gray[Query the SQL data warehouse:-]') \n",
    "    st.write(\"You can use SQL queries to join the tables in the SQL data warehouse and retrieve data for specific channels based on user input. You can use a Python SQL library such as SQLAlchemy to interact with the SQL database.\")\n",
    "    st.subheader(':gray[Display data in the Streamlit app:-]') \n",
    "    st.write(\"Finally, you can display the retrieved data in the Streamlit app. You can use Streamlit's data visualization features to create charts and graphs to help users analyze the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Menu == \"Data Transfer\":\n",
    "    ID = st.text_input(\"Enter Channel ID\")\n",
    "    channels = ID.split(',')\n",
    "    channels = [ch.strip() for ch in channels if ch]\n",
    "    if st.button(\"Collect & Store\"):\n",
    "        for channel in channels:\n",
    "            ch_ids = []\n",
    "            db = client[\"Youtube_data\"]\n",
    "            collection1 = db[\"Channel_Datas\"]\n",
    "            for ch_data in collection1.find({},{\"_id\":0,\"Channel_Details\":1}):\n",
    "                ch_ids.append(ch_data[\"Channel_Details\"][\"channel_id\"])\n",
    "            if channel in ch_ids:\n",
    "                st.success(\"Channel details of the given channel id: \" + channel + \" already exists\")\n",
    "            else:\n",
    "                output = Channel_Details(channel)\n",
    "                st.success(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Menu == \"Migrate Date\":\n",
    "    def mongo_connect():\n",
    "        client = MongoClient(\"mongodb+srv://syedafif9028:syed9028@cluster0.zukmabg.mongodb.net/?retryWrites=true&w=majority\")\n",
    "        db = client[\"Youtube_data\"]\n",
    "        collection1 = db[\"Channel_Datas\"]\n",
    "        return collection1\n",
    "    def list_channel():\n",
    "        coll=mongo_connect()\n",
    "        list_channels=[i[\"Channel_Details\"][\"channel_name\"] for i in coll.find({})]\n",
    "        return list_channels\n",
    "    \n",
    "    channel_names=st.selectbox(\"Select the Channel\",list_channel())\n",
    "\n",
    "    if st.button(\"Migrate Data to SQL\"):\n",
    "        display = Tables()\n",
    "        st.success(display)\n",
    "\n",
    "    show_table = st.sidebar.radio(\":red[*Select The Table For View:-*]\",(\":blue[channels]\",\":blue[videos]\",\":blue[comments]\"))\n",
    "\n",
    "    if show_table == \":blue[channels]\":\n",
    "        show_channel_table()\n",
    "    elif show_table ==\":blue[videos]\":\n",
    "        show_video_table()\n",
    "    elif show_table == \":blue[comments]\":\n",
    "        show_comment_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Menu == \"Query\":\n",
    "    Questions=st.selectbox(\n",
    "        \":red[*Please Sellect:-*]\",\n",
    "                            ('1. All Videos and Their Channel Name',\n",
    "                            '2. Channels have the most number of videos and their Counts',\n",
    "                            '3. Top 10 most viewed videos and their Channels',\n",
    "                            '4. Number of Comments on Each Video  and their Names',\n",
    "                            '5. Vidoes with Highest Likes and Their Channel Name',\n",
    "                            '6. Number of Likes for Videos and Their Names',\n",
    "                            '7. Number of Views for Channels',\n",
    "                            '8. Channel Name those Published Video in 2022',\n",
    "                            '9. Average Duration of All Videos in Each Channel with channel Name',\n",
    "                            '10. Vidoes with Highest Number of Comments and Their Channel Names'))\n",
    "\n",
    "    if Questions == '1. All Videos and Their Channel Name':\n",
    "        query1 = '''select Title as videos, Channel_Name as ChannelName from videos;'''\n",
    "        mycursor.execute(query1)\n",
    "        t1=mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t1, columns=[\"Video Title\",\"Channel Name\"]))\n",
    "\n",
    "    elif Questions == '2. Channels have the most number of videos and their Counts':\n",
    "        query2 = '''select channel_name as ChannelName,channel_videos as No_of_Videos from channels order by channel_videos desc;'''\n",
    "        mycursor.execute(query2)\n",
    "        t2=mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t2, columns=[\"Channel Name\",\"No Of Videos\"]))\n",
    "\n",
    "    elif Questions == '3. Top 10 most viewed videos and their Channels':\n",
    "        query3 = '''select Views as views , Channel_Name as ChannelName,Title as VideoTitle from videos\n",
    "                    where Views is not null order by Views desc limit 10;'''\n",
    "        mycursor.execute(query3)\n",
    "        t3 = mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t3, columns = [\"Views\",\"Channel Name\",\"Video Title\"]))\n",
    "\n",
    "    elif Questions == '4. Number of Comments on Each Video  and their Names':\n",
    "        query4 = '''select Comments as No_of_comments ,Title as VideoTitle from videos where Comments is not null;'''\n",
    "        mycursor.execute(query4)\n",
    "        t4 = mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t4, columns = [\"No of Comments\",\"Video Title\"]))\n",
    "\n",
    "    elif Questions == '5. Vidoes with Highest Likes and Their Channel Name':\n",
    "        query5 = '''select Title as VideoTitle, Channel_Name as ChannelName, Likes as LikesCount from videos \n",
    "                    where Likes is not null order by Likes desc;'''\n",
    "        mycursor.execute(query5)\n",
    "        t5 = mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t5, columns=[\"Video Title\",\"Channel Name\",\"Like Count\"]))\n",
    "\n",
    "    elif Questions == '6. Number of Likes for Videos and Their Names':\n",
    "        query6 = '''select Likes as likeCount,Title as VideoTitle from videos;'''\n",
    "        mycursor.execute(query6)\n",
    "        t6 = mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t6, columns=[\"Like Count\",\"Video Title\"]))\n",
    "\n",
    "    elif Questions == '7. Number of Views for Channels':\n",
    "        query7 = '''select channel_name as ChannelName, channel_views as Channelviews from channels;'''\n",
    "        mycursor.execute(query7)\n",
    "        t7=mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t7, columns=[\"Channel Name\",\"Total Views\"]))\n",
    "\n",
    "    elif Questions == '8. Channel Name those Published Video in 2022':\n",
    "        query8 = '''select Title as Video_Title, Published_Date as VideoRelease, Channel_Name as ChannelName from videos \n",
    "                    where extract(year from Published_Date) = 2022;'''\n",
    "        mycursor.execute(query8)\n",
    "        t8=mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t8,columns=[\"Name\", \"Video Publised On\", \"ChannelName\"]))\n",
    "\n",
    "    elif Questions == '9. Average Duration of All Videos in Each Channel with channel Name':\n",
    "        query9 =  '''SELECT Channel_Name as ChannelName, AVG(Duration) AS average_duration FROM videos GROUP BY Channel_Name;'''\n",
    "        mycursor.execute(query9)\n",
    "        t9=mycursor.fetchall()\n",
    "        t9 = pd.DataFrame(t9, columns=[\"ChannelName\", \"average_duration\"])\n",
    "        T9=[]\n",
    "        for index, row in t9.iterrows():\n",
    "            channel_title = row['ChannelName']\n",
    "            average_duration = row['average_duration']\n",
    "            average_duration_str = seconds_to_iso8601(average_duration)\n",
    "            T9.append({\"ChannelName\": channel_title ,  \"average_duration\": average_duration_str})\n",
    "        st.write(pd.DataFrame(T9)) \n",
    "\n",
    "    elif Questions == '10. Vidoes with Highest Number of Comments and Their Channel Names':\n",
    "        query10 = '''select Title as VideoTitle, Channel_Name as ChannelName, Comments as Comments from videos \n",
    "                        where Comments is not null order by Comments desc;'''\n",
    "        mycursor.execute(query10)\n",
    "        t10=mycursor.fetchall()\n",
    "        st.write(pd.DataFrame(t10, columns=['Video Title', 'Channel Name', 'NO Of Comments']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
